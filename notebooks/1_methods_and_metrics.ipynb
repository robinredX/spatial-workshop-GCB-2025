{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d79b971-ada8-4774-8902-5e625c4c69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053393f-4ade-4af9-b146-be74ea325dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('xenium_kidney_preprocessed.h5ad')\n",
    "\n",
    "print(f\"Full data shape: {adata.shape}\")\n",
    "print(f\"Samples: {adata.obs['sample'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62311342-4725-429f-8330-cae9bcbbac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BayesSpace\n",
    "try:\n",
    "    import rpy2.robjects as robjects\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    from rpy2.robjects.packages import importr\n",
    "    pandas2ri.activate()\n",
    "    \n",
    "    base = importr('base')\n",
    "    bayesspace = importr('BayesSpace')\n",
    "    singlecellexp = importr('SingleCellExperiment')\n",
    "    \n",
    "    print(\"BayesSpace loaded successfully\")\n",
    "    BAYESSPACE_AVAILABLE = True\n",
    "except:\n",
    "    print(\"BayesSpace not available, using alternative clustering\")\n",
    "    BAYESSPACE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca92a0-1cb8-491e-90b7-2e05168d0115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ac49e-7e56-420a-8ab8-78e77bea3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph computation\n",
    "\n",
    "for sample in adata.obs['sample'].unique():\n",
    "    sample_mask = adata.obs['sample'] == sample\n",
    "    sample_data = adata[sample_mask].copy()\n",
    "    \n",
    "    sq.gr.spatial_neighbors(sample_data, coord_type='generic', n_neighs=6)\n",
    "    \n",
    "    if 'spatial_connectivities' not in adata.obsp.keys():\n",
    "        adata.obsp['spatial_connectivities'] = np.zeros((adata.n_obs, adata.n_obs))\n",
    "        adata.obsp['spatial_distances'] = np.zeros((adata.n_obs, adata.n_obs))\n",
    "    \n",
    "    sample_indices = np.where(sample_mask)[0]\n",
    "    for i, idx_i in enumerate(sample_indices):\n",
    "        for j, idx_j in enumerate(sample_indices):\n",
    "            adata.obsp['spatial_connectivities'][idx_i, idx_j] = sample_data.obsp['spatial_connectivities'][i, j]\n",
    "            adata.obsp['spatial_distances'][idx_i, idx_j] = sample_data.obsp['spatial_distances'][i, j]\n",
    "\n",
    "print(\"Spatial neighborhood graph constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a80b72-64a4-419a-9ffa-69735c6b49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bayesspace_clustering(adata_sample, n_clusters=7, n_hvg=2000):\n",
    "    coords_df = pd.DataFrame(adata_sample.obsm['spatial'], columns=['x', 'y'])\n",
    "    coords_df.index = adata_sample.obs.index\n",
    "    \n",
    "    expr_df = pd.DataFrame(adata_sample.X.toarray() if hasattr(adata_sample.X, 'toarray') else adata_sample.X,\n",
    "                          index=adata_sample.obs.index, \n",
    "                          columns=adata_sample.var.index)\n",
    "    \n",
    "    robjects.globalenv['coords_r'] = pandas2ri.py2rpy(coords_df)\n",
    "    robjects.globalenv['expr_r'] = pandas2ri.py2rpy(expr_df)\n",
    "    robjects.globalenv['n_clusters'] = n_clusters\n",
    "    \n",
    "    r_script = f\"\"\"\n",
    "    library(BayesSpace)\n",
    "    library(SingleCellExperiment)\n",
    "    \n",
    "    sce <- SingleCellExperiment(assays=list(logcounts=t(expr_r)),\n",
    "                               colData=coords_r)\n",
    "    \n",
    "    sce <- spatialPreprocess(sce, platform=\"Visium\", n.PCs=50, n.HVGs={n_hvg})\n",
    "    sce <- qTune(sce, qs=seq(2, 10), platform=\"Visium\", d=50)\n",
    "    sce <- spatialCluster(sce, q={n_clusters}, platform=\"Visium\", d=50,\n",
    "                         init.method=\"mclust\", model=\"t\", gamma=2,\n",
    "                         nrep=1000, burn.in=100)\n",
    "    \n",
    "    clusters <- sce$spatial.cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    robjects.r(r_script)\n",
    "    clusters = robjects.r['clusters']\n",
    "    \n",
    "    return pd.Categorical(list(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb9057-8d42-4b6c-b34c-32fb44f5a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesspace_results = {}\n",
    "\n",
    "for sample in adata.obs['sample'].unique():\n",
    "    print(f\"Running BayesSpace on {sample}...\")\n",
    "    sample_mask = adata.obs['sample'] == sample\n",
    "    sample_data = adata[sample_mask].copy()\n",
    "    \n",
    "    clusters = run_bayesspace_clustering(sample_data, n_clusters=8)\n",
    "    bayesspace_results[sample] = clusters\n",
    "    \n",
    "    adata.obs.loc[sample_mask, 'bayesspace_domains'] = clusters\n",
    "\n",
    "print(\"BayesSpace clustering completed\")\n",
    "print(f\"Domain counts per sample:\")\n",
    "for sample in adata.obs['sample'].unique():\n",
    "    sample_counts = adata.obs[adata.obs['sample'] == sample]['bayesspace_domains'].value_counts()\n",
    "    print(f\"{sample}: {dict(sample_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8edd980-4135-451d-8c6e-c7d3db727d36",
   "metadata": {},
   "source": [
    "## nichePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c5405-750a-4419-b1e1-423d1c077a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nichepca(adata_sample, n_components=10, neighborhood_size=50):\n",
    "    coords = adata_sample.obsm['spatial']\n",
    "    expr_data = adata_sample.X.toarray() if hasattr(adata_sample.X, 'toarray') else adata_sample.X\n",
    "    \n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=neighborhood_size, algorithm='ball_tree').fit(coords)\n",
    "    distances, indices = nbrs.kneighbors(coords)\n",
    "    \n",
    "    niche_profiles = np.zeros((adata_sample.n_obs, adata_sample.n_vars))\n",
    "    \n",
    "    for i in range(adata_sample.n_obs):\n",
    "        neighbor_indices = indices[i]\n",
    "        weights = 1 / (distances[i] + 1e-8)  \n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        niche_profiles[i] = np.average(expr_data[neighbor_indices], axis=0, weights=weights)\n",
    "    \n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    niche_pca = pca.fit_transform(niche_profiles)\n",
    "    \n",
    "    return niche_pca, pca\n",
    "\n",
    "def run_nichepca_clustering(adata_sample, n_components=10, n_clusters=8):\n",
    "    niche_pca, pca_model = compute_nichepca(adata_sample, n_components=n_components)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)\n",
    "    clusters = kmeans.fit_predict(niche_pca)\n",
    "    \n",
    "    return clusters, niche_pca, pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b86faba-43d6-40c4-9052-5dc637a21640",
   "metadata": {},
   "outputs": [],
   "source": [
    "nichepca_results = {}\n",
    "nichepca_embeddings = {}\n",
    "\n",
    "for sample in adata.obs['sample'].unique():\n",
    "    print(f\"Running nichePCA on {sample}...\")\n",
    "    sample_mask = adata.obs['sample'] == sample\n",
    "    sample_data = adata[sample_mask].copy()\n",
    "    \n",
    "    clusters, niche_embedding, pca_model = run_nichepca_clustering(sample_data, n_components=15, n_clusters=8)\n",
    "    \n",
    "    nichepca_results[sample] = clusters\n",
    "    nichepca_embeddings[sample] = niche_embedding\n",
    "    \n",
    "    adata.obs.loc[sample_mask, 'nichepca_domains'] = clusters.astype(str)\n",
    "\n",
    "print(\"nichePCA clustering completed\")\n",
    "print(f\"Domain counts per sample:\")\n",
    "for sample in adata.obs['sample'].unique():\n",
    "    sample_counts = adata.obs[adata.obs['sample'] == sample]['nichepca_domains'].value_counts()\n",
    "    print(f\"{sample}: {dict(sample_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5160969-7487-4b0d-b092-73ce1efa0049",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498b036-d39b-44d9-9dcf-899a0fe88bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spatial_coherence(adata_sample, cluster_key):\n",
    "    coords = adata_sample.obsm['spatial']\n",
    "    clusters = adata_sample.obs[cluster_key]\n",
    "    \n",
    "    coherence_scores = []\n",
    "    \n",
    "    for cluster_id in clusters.unique():\n",
    "        cluster_mask = clusters == cluster_id\n",
    "        if cluster_mask.sum() < 3:\n",
    "            continue\n",
    "            \n",
    "        cluster_coords = coords[cluster_mask]\n",
    "        \n",
    "        if len(cluster_coords) > 1:\n",
    "            distances = pdist(cluster_coords)\n",
    "            mean_intra_distance = np.mean(distances)\n",
    "            \n",
    "            other_coords = coords[~cluster_mask]\n",
    "            if len(other_coords) > 0:\n",
    "                inter_distances = []\n",
    "                for coord in cluster_coords:\n",
    "                    dist_to_others = np.sqrt(((other_coords - coord) ** 2).sum(axis=1))\n",
    "                    inter_distances.extend(dist_to_others)\n",
    "                \n",
    "                mean_inter_distance = np.mean(inter_distances)\n",
    "                coherence = mean_inter_distance / (mean_intra_distance + 1e-8)\n",
    "                coherence_scores.append(coherence)\n",
    "    \n",
    "    return np.mean(coherence_scores) if coherence_scores else 0\n",
    "\n",
    "def calculate_silhouette_spatial(adata_sample, cluster_key):\n",
    "    coords = adata_sample.obsm['spatial']\n",
    "    clusters = adata_sample.obs[cluster_key]\n",
    "    \n",
    "    if len(clusters.unique()) < 2:\n",
    "        return 0\n",
    "    \n",
    "    cluster_labels = pd.Categorical(clusters).codes\n",
    "    sil_score = silhouette_score(coords, cluster_labels)\n",
    "    \n",
    "    return sil_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544cb62-aa27-423a-a5ac-d1013b9e9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = {}\n",
    "\n",
    "for sample in adata.obs['sample'].unique():\n",
    "    sample_mask = adata.obs['sample'] == sample\n",
    "    sample_data = adata[sample_mask].copy()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for method, cluster_key in [('BayesSpace', 'bayesspace_domains'), \n",
    "                               ('nichePCA', 'nichepca_domains')]:\n",
    "        \n",
    "        spatial_coherence = calculate_spatial_coherence(sample_data, cluster_key)\n",
    "        silhouette_spatial = calculate_silhouette_spatial(sample_data, cluster_key)\n",
    "        \n",
    "        n_clusters = len(sample_data.obs[cluster_key].unique())\n",
    "        \n",
    "        results[method] = {\n",
    "            'spatial_coherence': spatial_coherence,\n",
    "            'silhouette_spatial': silhouette_spatial,\n",
    "            'n_clusters': n_clusters\n",
    "        }\n",
    "    \n",
    "    evaluation_results[sample] = results\n",
    "\n",
    "evaluation_df = pd.DataFrame({\n",
    "    (sample, method): metrics \n",
    "    for sample, sample_results in evaluation_results.items()\n",
    "    for method, metrics in sample_results.items()\n",
    "}).T\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(evaluation_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16a2fb-fbfc-46a3-894f-e360b65af2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BayesSpace\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "for i, sample in enumerate(adata.obs['sample'].unique()):\n",
    "    sample_mask = adata.obs['sample'] == sample\n",
    "    sample_data = adata[sample_mask]\n",
    "    coords = sample_data.obsm['spatial']\n",
    "    clusters = sample_data.obs['bayesspace_domains']\n",
    "    \n",
    "    unique_clusters = clusters.unique()\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_clusters)))\n",
    "    \n",
    "    for j, cluster in enumerate(unique_clusters):\n",
    "        cluster_mask = clusters == cluster\n",
    "        axes[i].scatter(coords[cluster_mask, 0], coords[cluster_mask, 1], \n",
    "                       c=[colors[j]], s=1, alpha=0.7, label=f'Domain {cluster}')\n",
    "    \n",
    "    axes[i].set_title(f'BayesSpace Domains - {sample}')\n",
    "    axes[i].set_xlabel('X coordinate')\n",
    "    axes[i].set_ylabel('Y coordinate')\n",
    "    axes[i].axis('equal')\n",
    "    axes[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a073ad-b414-4ca1-bdb8-98da7308e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "for i, sample in enumerate(adata.obs['sample'].unique()):\n",
    "    sample_mask = adata.obs['sample'] == sample\n",
    "    sample_data = adata[sample_mask]\n",
    "    coords = sample_data.obsm['spatial']\n",
    "    clusters = sample_data.obs['nichepca_domains']\n",
    "    \n",
    "    unique_clusters = clusters.unique()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_clusters)))\n",
    "    \n",
    "    for j, cluster in enumerate(unique_clusters):\n",
    "        cluster_mask = clusters == cluster\n",
    "        axes[i].scatter(coords[cluster_mask, 0], coords[cluster_mask, 1], \n",
    "                       c=[colors[j]], s=1, alpha=0.7, label=f'Domain {cluster}')\n",
    "    \n",
    "    axes[i].set_title(f'nichePCA Domains - {sample}')\n",
    "    axes[i].set_xlabel('X coordinate')\n",
    "    axes[i].set_ylabel('Y coordinate')\n",
    "    axes[i].axis('equal')\n",
    "    axes[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8397101-2ed5-453c-9d49-ede05df7845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('xenium_kidney_with_domains.h5ad')\n",
    "\n",
    "results_summary = {\n",
    "    'evaluation_metrics': evaluation_df,\n",
    "    'bayesspace_results': bayesspace_results,\n",
    "    'nichepca_results': nichepca_results,\n",
    "    'nichepca_embeddings': nichepca_embeddings\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open('spatial_domain_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results_summary, f)\n",
    "\n",
    "print(\"Results saved successfully\")\n",
    "print(\"\\nFinal domain counts:\")\n",
    "print(\"BayesSpace:\")\n",
    "print(adata.obs.groupby('sample')['bayesspace_domains'].value_counts())\n",
    "print(\"\\nnichePCA:\")\n",
    "print(adata.obs.groupby('sample')['nichepca_domains'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaa22b2-b7ab-43fd-8857-a7559dd38ab3",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "1. Implement nichePCA with cell type labels rather than gene expression. A similar approach is [MENDER](https://www.nature.com/articles/s41467-023-44367-9).\n",
    "\n",
    "2. Assign compartment names (e.g. glomerular, tubules) based on the gene expression and annotated domains.\n",
    "\n",
    "3. Align domains across samples. For nichePCA, a batch correction algorithm can be used on aggregated gene expression.\n",
    "\n",
    "4. (optional) Implement multi-resolution spatial domains, e.g. with hierarchial clustering or [SCALE](https://www.biorxiv.org/content/10.1101/2025.05.21.653987v1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9b9ea-f410-4754-8b3e-6e6534aa6331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium_cgn_1",
   "language": "python",
   "name": "xenium_cgn_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
